{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression assumes that the response data are *homoscedastic* , that is, the responses have a constant variance in theri errors\n",
        "\n",
        "If this is not the case, then linear regression provides less precision in the estimation of parameters\n",
        "\n",
        "In finance, we use descriptive statistics of historical price data. We use moments of the data; such as mean, variance, skew, and kurtosis. Such models rely on these moments being constant in time. Under a market regime change these moments are drastically altered and the model degrades.\n",
        "\n",
        "Instead, we use models rolling parameters to mitigate issue and consider how the descriptive parameters alter with time."
      ],
      "metadata": {
        "id": "8XTUCHvquIiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kelly Criterion\n",
        "Before we jump onto it , let us understand some assumptions we make with this criterion\n",
        "\n",
        "1. The return stream is normally distributed ; each strategy has a fixed mean and standard deviation of returns, that is, the values do not change with time. This makes for a bad assumption but an easy formula\n",
        "\n",
        "2. The returns considered are excess returns, after deducting costs\n",
        "\n",
        "3. It is assumed that all of the trading profits are reinvested\n",
        "\n",
        "4. All of the strategies are statistically independent and therefore the correlation matrix is diagonal\n",
        "\n",
        "\n",
        "Let us imagine that we have a set of *N* algorithmic trading strategies and we wish to determine two things :\n",
        "\n",
        "1. How to apply optimal leverage per strategy in order to maximize growth rate and minimize drawdowns\n",
        "\n",
        "2. How to allocate capital between each strategy\n",
        "\n",
        "\n",
        "If we denote the allocation between each strategy i as a vector f of length N, s.t.\n",
        "f = (f1, ..., fN ), then the Kelly Criterion for optimal allocation to each strategy fi\n",
        "is given by:\n",
        "fi = µ_i/σ_i^2\n",
        "\n",
        "Where µi are the mean excess returns and σi are the standard deviation of excess returns for\n",
        "a strategy i. This formula essentially describes the optimal leverage that should be applied to\n",
        "each strategy.\n",
        "\n",
        "While the Kelly Criterion fi gives us the optimal leverage and strategy allocation, we still\n",
        "need to actually calculate our expected long-term compounded growth rate of the portfolio,\n",
        "which we denote by g. The formula for this is given by:\n",
        "g = r + S^2/2\n",
        "Where r is the risk-free interest rate, which is the rate at which you can borrow from the\n",
        "broker, and S is the annualised Sharpe Ratio of the strategy. The latter is calculated via the\n",
        "annualised mean excess returns divided by the annualised standard deviations of excess returns.\n",
        "\n"
      ],
      "metadata": {
        "id": "8V66qzRhwH1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Risk Management\n",
        "\n",
        "**Value at Risk**\n",
        "\n",
        "Estimating the risk of loss on a portfolio of strategies is of extreme importance.\n",
        "\n",
        "Many techniques for risk management have been developed, and a particularly popular one is Value-at-Risk , or VaR\n",
        "\n",
        "**VaR**\n",
        "VaR provides us an estimate , with some degree of confidence, of the size of loss from a portfolio over a given period of time\n",
        "\n",
        "The time period is chosen to reflect the time in which there would be minimal market impact if a portfolio was completely sold (liquidated , in market terminology)\n",
        "\n",
        "Assume a VaR equal to $500000 at 95% confidence level for a day ; this implies that there is probability of 95% of losing no more than $500000 in the following day\n",
        "\n",
        "Mathematically,\n",
        "\n",
        "*P(L ≤ -5e5)  = 0.05*\n",
        "\n",
        "In general terms, for loss L exceeding a value VaR with a confidence level c , we can write mathematically as :\n",
        "\n",
        "*P(L ≤ -Var) = 1 - c*\n",
        "\n",
        "Following are the **assumptions** of VaR calculation :\n",
        "\n",
        "1. Standard Market Conditions : VaR does not consider extreme events ; it provides expectation of loss under day to day events\n",
        "2. Volatilities and Correlations : We require volatilities of assets under consideration alongwith their respective correlations ; basically the variance-covariance matrix\n",
        "3. Normality of Returns : VaR , in its standard form, assumes that the returns of an asset and portfolio are normally distributed ; this makes calculations easier but the model unrealistic\n",
        "\n",
        "\n",
        "**Advantages of VaR Model**\n",
        "\n",
        "1. Straightfroward calculations and interpretation\n",
        "2. Time period associated can be modified and strategies can be analysed across varying time frames\n",
        "3. Different values of VaR can be used to describe different types of risks ; example, classification by asset class or instrument type\n",
        "4. Individual strategies can be constrained as can entire portfolios based on individual VaR\n",
        "\n",
        "**Disadvantages of VaR**\n",
        "\n",
        "1. VaR does not discuss the magnitude of expected loss *beyond* the value of VaR\n",
        "2. Extreme events are not accounted for\n",
        "3. Future market regime shift that may change volatilities and correlation factors are not accounted\n",
        "\n",
        "VaR should not be used in isolation ; it should be used with other risk management techniques such as diversification of assets, portfolio optimization, and prudent use of leverage\n",
        "\n"
      ],
      "metadata": {
        "id": "ypMNJ_fMzFst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculatin VaR by Variance-Covariance Method"
      ],
      "metadata": {
        "id": "c6cPqPJmoc2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndp1tWbyp8yp",
        "outputId": "3f166682-3e66-4ad5-9180-58396bdb0523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VaR =  36509.4156256906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Consider a portfolio of P dollars, with a confidence level c ; we consider daily returns\n",
        "# here, with strategy's historical standard deviation sigma and mean mu\n",
        "# The daily VaR is given as the below formula, where alpha is the percentage point function\n",
        "# which essentially is nothing but the inverse of the characteristic distribution function\n",
        "\n",
        "def varCov(P, c, mu, sigma) :\n",
        "  alpha  = norm.ppf(1-c, mu, sigma)\n",
        "  return P - P*(alpha+1)\n",
        "\n",
        "if __name__ ==  \"__main__\" :\n",
        "  start = datetime.datetime(2023, 1, 1)\n",
        "  end = datetime.datetime(2024,1,1)\n",
        "\n",
        "  asset = yf.download(\"C\", start, end)\n",
        "  asset[\"returns\"] = asset[\"Adj Close\"].pct_change()\n",
        "  asset = asset.dropna()\n",
        "  P = 1e6\n",
        "  c = 0.99\n",
        "  mu = np.mean(asset[\"returns\"])\n",
        "  sigma = np.std(asset[\"returns\"])\n",
        "  var = varCov(P, c, mu, sigma)\n",
        "  print(\"VaR = \", var)\n",
        "\n",
        "  # asset = yf.download(\"AMZN\", start, end)\n",
        "  # asset[\"returns\"] = asset[\"Adj Close\"].pct_change()\n",
        "  # asset = asset.dropna()\n",
        "  # P = 1e6\n",
        "  # c = 0.99\n",
        "  # mu = np.mean(asset[\"returns\"])\n",
        "  # sigma = np.std(asset[\"returns\"])\n",
        "  # var = varCov(P, c, mu, sigma)\n",
        "  # print(\"VaR = \", var)\n",
        "\n",
        "  # asset = yf.download(\"GOOG\", start, end)\n",
        "  # asset[\"returns\"] = asset[\"Adj Close\"].pct_change()\n",
        "  # asset = asset.dropna()\n",
        "  # P = 1e6\n",
        "  # c = 0.99\n",
        "  # mu = np.mean(asset[\"returns\"])\n",
        "  # sigma = np.std(asset[\"returns\"])\n",
        "  # var = varCov(P, c, mu, sigma)\n",
        "  # print(\"VaR = \", var)\n",
        "\n",
        "  # asset = yf.download(\"NVDA\", start, end)\n",
        "  # asset[\"returns\"] = asset[\"Adj Close\"].pct_change()\n",
        "  # asset = asset.dropna()\n",
        "  # P = 1e6\n",
        "  # c = 0.99\n",
        "  # mu = np.mean(asset[\"returns\"])\n",
        "  # sigma = np.std(asset[\"returns\"])\n",
        "  # var = varCov(P, c, mu, sigma)\n",
        "  # print(\"VaR = \", var)"
      ]
    }
  ]
}
